# llama-3.2-3b-openhermes
This repo contains a fine-tuned LLaMA 3.2B model served using vLLM and Docker. The project includes a custom OpenAI-style API endpoint, benchmarking scripts, performance metrics, and monitoring setup. Designed for low-latency inference and production-ready LLM deployment.
